{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instaloader\n",
    "import re #regular expressions\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from os import path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "import itertools\n",
    "import time\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mozilla/5.0 (iPhone; CPU iPhone OS 15_6_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 Instagram 248.1.0.13.112 (iPhone11,2; iOS 15_6_1; en_US; en-US; scale=3.00; 1125x2436; 390885564) NW/3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('instagram_mobile_user_agent.txt', 'r') as f:\n",
    "    mobile_user_agent = f.read()\n",
    "mobile_user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded session from C:\\Users\\kas1112\\AppData\\Local\\Instaloader\\session-kazimiersmith.\n"
     ]
    }
   ],
   "source": [
    "# Get instance. Use iphone user agent so requests to Instagram look less suspicious\n",
    "L = instaloader.Instaloader(user_agent = mobile_user_agent)\n",
    "\n",
    "# Login to Instagram using session file created with instaloader --login in terminal.\n",
    "# Each person running the code needs to do this themselves. Instagram seems to require being logged in to access most information.\n",
    "# Don't use an account you care a lot about - it could get banned due to scraping\n",
    "L.load_session_from_file('kazimiersmith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "influencer_list_full = pd.read_csv('list_influencers.csv', encoding = 'utf-8')\n",
    "#influencer_list_full = pd.read_csv('list_influencers_5.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the initial regression of engagement on sponsorship, use influencers with\n",
    "# 50,000 to 200,000 followers\n",
    "influencer_list = influencer_list_full[(influencer_list_full['num_followers'] > 50000) \n",
    "                                       & (influencer_list_full['num_followers'] < 200000)]['username']\n",
    "#influencer_list = influencer_list_full['username']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_to_json(influencer, num_posts, replace_json = True):\n",
    "    print('Downloading posts from', influencer)\n",
    "    Profile = instaloader.Profile\n",
    "    profile = Profile.from_username(L.context, influencer)\n",
    "\n",
    "    # TODO does get_posts return the most recent posts first?\n",
    "    posts = profile.get_posts()\n",
    "    \n",
    "    for post in itertools.islice(posts, num_posts):\n",
    "        shortcode = post.shortcode\n",
    "        path = os.path.join(os.path.join(os.getcwd(), 'json'), shortcode)\n",
    "        if replace_json or not path.exists(path + '.json.xz'):\n",
    "            L.save_metadata_json(path, post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: if the json subfolder exists from a previous run, it may contain files corresponding to posts that aren't in the five\n",
    "# most recent posts of a given influencer anymore. So, delete the json subfolder\n",
    "json_path = os.path.join(os.getcwd(), 'json')\n",
    "if path.exists(json_path):\n",
    "   rmtree('json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading posts from fooddolls\n",
      "json json json json json Downloading posts from nycfoodcoma\n",
      "json json json json json Downloading posts from therealfoodrds\n",
      "Downloading posts from dadaeats\n",
      "json json json json json Downloading posts from wholesome_lee\n",
      "json json json json json Downloading posts from upbeetandkaleingit\n",
      "json json json json json Downloading posts from fitmittenkitchen\n",
      "json json json json json Downloading posts from purely_elizabeth\n",
      "json json json json json Downloading posts from healthymoodsf\n",
      "json json json json json Downloading posts from thecuttingveg\n",
      "json json json json json Downloading posts from mississippivegan\n",
      "json json json json json Downloading posts from byanjushka\n",
      "json json json json json Downloading posts from laurafruitfairy\n",
      "json json json json json Downloading posts from lastingredient\n",
      "json json json json json Downloading posts from localhaven\n",
      "json json json json json Downloading posts from melissas_healthykitchen\n",
      "json json json json json Downloading posts from healthfulradiance\n",
      "json json json json json Downloading posts from wellplated\n",
      "json json json json json Downloading posts from twist_of_lemons\n",
      "json json json json json Downloading posts from ny.foodie\n",
      "json json json json json Downloading posts from cleanfooddirtycity\n",
      "json json json json json Downloading posts from thecarboholic\n",
      "json json json json json Downloading posts from dollyandoatmeal\n",
      "json json json json json Downloading posts from tashcakes.tastes\n",
      "json json json json json Downloading posts from oliveyouwhole\n",
      "json json json json json Downloading posts from no.food.rules\n",
      "json json json json json Downloading posts from lizmoody\n",
      "json json json json json Downloading posts from onebalancedlife\n",
      "json json json json json Downloading posts from thewholecook\n",
      "json json json json json Downloading posts from abbeyskitchen\n",
      "json json json json json Downloading posts from dietitiandeanna\n",
      "json json json json json Downloading posts from foodfitnessandfaith\n",
      "json json json json json Downloading posts from the_bananadiaries\n",
      "json json json json json Downloading posts from gatherednutrition\n",
      "json json json json json Downloading posts from thefullhelping\n",
      "json json json json json Downloading posts from mateo.zielonka\n",
      "json json json json json Downloading posts from shuangys_kitchensink\n",
      "json json json json json Downloading posts from beautifuleatsandthings\n",
      "json json json json json Downloading posts from marie.reginato\n",
      "json json json json json Downloading posts from unboundwellness\n",
      "json json json json json Downloading posts from diet.culture.rebel\n",
      "json json json json json Downloading posts from dani_nemeh\n",
      "json json json json json Downloading posts from dad_beets\n",
      "json json json json json Downloading posts from foodheaven\n",
      "json json json json json Downloading posts from eatingwith_em\n",
      "json json json json json Downloading posts from thehealthyhaff\n",
      "json json json json json Downloading posts from adventuresofape\n",
      "json json json json json Downloading posts from cookandsavor\n",
      "json json json json json Downloading posts from chickpeachick_\n",
      "json json json json json Downloading posts from danishealthyeats\n",
      "json json json json json Downloading posts from fitstrongshann\n",
      "json json json json json Downloading posts from wildlywholesome\n",
      "json json json json json "
     ]
    }
   ],
   "source": [
    "for influencer in influencer_list:\n",
    "    user_to_json(influencer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grab objects of interest from post object\n",
    "\n",
    "def objects_from_post(post):\n",
    "    # Shortcode\n",
    "    shortcode = 'https://www.instagram.com/p/' + post.shortcode\n",
    "    \n",
    "    # Date\n",
    "    postdate = post.date\n",
    "    \n",
    "    # Profile\n",
    "    profile = post.owner_profile\n",
    "    \n",
    "    # Username of post's owner\n",
    "    profile_username = post.owner_username\n",
    "    \n",
    "    # Extract location\n",
    "    location = post.location\n",
    "    #location = None\n",
    "    \n",
    "    if not location:\n",
    "        loc_name = float('nan')\n",
    "        loc_lng = float('nan')\n",
    "        loc_lat = float('nan')\n",
    "    else:\n",
    "        loc_name = location.name\n",
    "        loc_lng = location.lng\n",
    "        loc_lat = location.lat\n",
    "        \n",
    "    # Extract image URL\n",
    "    image_url = post.url\n",
    "    \n",
    "    # Number of likes\n",
    "    likes_num = post.likes \n",
    "    \n",
    "    # Number of comments\n",
    "    comments_num = post.comments\n",
    "    \n",
    "    # Find ID of likes\n",
    "    #postlikes = []\n",
    "    #for likes in post.get_likes():\n",
    "    #    postlikes.append(likes)\n",
    "    \n",
    "    # Extract caption\n",
    "    # Caption\n",
    "    caption = post.caption\n",
    "    \n",
    "    # Caption hashtag\n",
    "    caption_hashtags = post.caption_hashtags\n",
    "    \n",
    "    # Caption mentions (profiles mentioned in caption)\n",
    "    caption_mention = post.caption_mentions\n",
    "    \n",
    "    # Whether the post is sponsored (i.e. \"Paid partnership with...\")\n",
    "    sponsored = post.is_sponsored\n",
    "    \n",
    "    # List of the post's sponsors (usernames)\n",
    "    sponsors = [p.username for p in post.sponsor_users]\n",
    "    \n",
    "    # Number of followers\n",
    "    followers_num = profile.followers\n",
    "    \n",
    "    # Chronologically earliest comment, to search for hashtags. Influencers sometimes put hashtags in a separate comment,\n",
    "    # usually the first comment on the post. Note that post.get_comments() does not necessarily return\n",
    "    # the chronologically earliest comment as the first item.\n",
    "#     start = time.time()\n",
    "#     first_comment = min(post.get_comments(), key = lambda p: p.created_at_utc)\n",
    "#     if first_comment:\n",
    "#         first_comment_text = first_comment.text\n",
    "        \n",
    "#         # Is the first comment by the owner of the original post?\n",
    "#         first_comment_by_owner = (first_comment.owner.username == profile_username)\n",
    "        \n",
    "#         # If the first comment is by the owner of the original post, get the (unique) hashtags from the first comment\n",
    "#         first_comment_hashtags = list(set(part[1:] for part in first_comment_text.split() if part.startswith('#')))\n",
    "#     else:\n",
    "#         first_comment_text = float('nan')\n",
    "#         first_comment_by_owner = float('nan')\n",
    "#         first_comment_hastags = float('nan')\n",
    "        \n",
    "#     end = time.time()\n",
    "#     print('Getting first comment hashtags took', str(end - start), 'seconds')\n",
    "    \n",
    "    if post.comments > 0:\n",
    "        owner_comments = (c for c in post.get_comments() if c.owner.username == profile_username)\n",
    "        owner_comment_hashtags = [part[1:] for c in owner_comments for part in c.text.split() if part.startswith('#')]\n",
    "        owner_comment_hashtags_unique = list(set(owner_comment_hashtags))\n",
    "    else:\n",
    "        owner_comment_hashtags_unique = float('nan')\n",
    "    \n",
    "    data = {'shortcode': shortcode,\n",
    "            'date': postdate,\n",
    "            'profile_username': profile_username,\n",
    "            'location_name': loc_name,\n",
    "            'location_lat': loc_lat,\n",
    "            'location_lng': loc_lng,\n",
    "            'image_url': image_url,\n",
    "            'likes_num': likes_num,\n",
    "            'comments_num': comments_num,\n",
    "            'caption': caption,\n",
    "            'caption_hashtags': caption_hashtags,\n",
    "            'caption_mention': caption_mention,\n",
    "            'sponsored': sponsored,\n",
    "            'sponsors': sponsors,\n",
    "            'followers_num': followers_num,\n",
    "            'owner_comment_hashtags': owner_comment_hashtags_unique}\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_dict(shortcode):\n",
    "    the_dict = {'shortcode': shortcode, \n",
    "                'date': float('nan'),\n",
    "                'profile_username': float('nan'),\n",
    "                'location_name': float('nan'),\n",
    "                'location_lat': float('nan'),\n",
    "                'location_lng': float('nan'),\n",
    "                'image_url': float('nan'),\n",
    "                'likes_num': float('nan'),\n",
    "                'comments_num': float('nan'),\n",
    "                'caption': float('nan'),\n",
    "                'caption_hashtags': float('nan'),\n",
    "                'caption_mention': float('nan'),\n",
    "                'sponsored': float('nan'),\n",
    "                'sponsors': float('nan'),\n",
    "                'followers_num': float('nan'),\n",
    "                'owner_comment_hashtags': float('nan')}\n",
    "    return the_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 1 of 255\n",
      "\n",
      "Post 2 of 255\n",
      "\n",
      "Post 3 of 255\n",
      "\n",
      "Post 4 of 255\n",
      "\n",
      "Post 5 of 255\n",
      "\n",
      "Post 6 of 255\n",
      "\n",
      "Post 7 of 255\n",
      "\n",
      "Post 8 of 255\n",
      "\n",
      "Post 9 of 255\n",
      "\n",
      "Post 10 of 255\n",
      "\n",
      "Post 11 of 255\n",
      "\n",
      "Post 12 of 255\n",
      "\n",
      "Post 13 of 255\n",
      "\n",
      "Post 14 of 255\n",
      "\n",
      "Post 15 of 255\n",
      "\n",
      "Post 16 of 255\n",
      "\n",
      "Post 17 of 255\n",
      "\n",
      "Post 18 of 255\n",
      "\n",
      "Post 19 of 255\n",
      "\n",
      "Post 20 of 255\n",
      "\n",
      "Post 21 of 255\n",
      "\n",
      "Post 22 of 255\n",
      "\n",
      "Post 23 of 255\n",
      "\n",
      "Post 24 of 255\n",
      "\n",
      "Post 25 of 255\n",
      "\n",
      "Post 26 of 255\n",
      "\n",
      "Post 27 of 255\n",
      "\n",
      "Post 28 of 255\n",
      "\n",
      "Post 29 of 255\n",
      "\n",
      "Post 30 of 255\n",
      "\n",
      "Post 31 of 255\n",
      "\n",
      "Post 32 of 255\n",
      "\n",
      "Post 33 of 255\n",
      "\n",
      "Post 34 of 255\n",
      "\n",
      "Post 35 of 255\n",
      "\n",
      "Post 36 of 255\n",
      "\n",
      "Post 37 of 255\n",
      "\n",
      "Post 38 of 255\n",
      "\n",
      "Post 39 of 255\n",
      "\n",
      "Post 40 of 255\n",
      "\n",
      "Post 41 of 255\n",
      "\n",
      "Post 42 of 255\n",
      "\n",
      "Post 43 of 255\n",
      "\n",
      "Post 44 of 255\n",
      "\n",
      "Post 45 of 255\n",
      "\n",
      "Post 46 of 255\n",
      "\n",
      "Post 47 of 255\n",
      "\n",
      "Post 48 of 255\n",
      "\n",
      "Post 49 of 255\n",
      "\n",
      "Post 50 of 255\n",
      "\n",
      "Post 51 of 255\n",
      "\n",
      "Post 52 of 255\n",
      "\n",
      "Post 53 of 255\n",
      "\n",
      "Post 54 of 255\n",
      "\n",
      "Post 55 of 255\n",
      "\n",
      "Post 56 of 255\n",
      "\n",
      "Post 57 of 255\n",
      "\n",
      "Post 58 of 255\n",
      "\n",
      "Post 59 of 255\n",
      "\n",
      "Post 60 of 255\n",
      "\n",
      "Post 61 of 255\n",
      "\n",
      "Post 62 of 255\n",
      "\n",
      "Post 63 of 255\n",
      "\n",
      "Post 64 of 255\n",
      "\n",
      "Post 65 of 255\n",
      "\n",
      "Post 66 of 255\n",
      "\n",
      "Post 67 of 255\n",
      "\n",
      "Post 68 of 255\n",
      "\n",
      "Post 69 of 255\n",
      "\n",
      "Post 70 of 255\n",
      "\n",
      "Post 71 of 255\n",
      "\n",
      "Post 72 of 255\n",
      "\n",
      "Post 73 of 255\n",
      "\n",
      "Post 74 of 255\n",
      "\n",
      "Post 75 of 255\n",
      "\n",
      "Post 76 of 255\n",
      "\n",
      "Post 77 of 255\n",
      "\n",
      "Post 78 of 255\n",
      "\n",
      "Post 79 of 255\n",
      "\n",
      "Post 80 of 255\n",
      "\n",
      "Post 81 of 255\n",
      "\n",
      "Post 82 of 255\n",
      "\n",
      "Post 83 of 255\n",
      "\n",
      "Post 84 of 255\n",
      "\n",
      "Post 85 of 255\n",
      "\n",
      "Post 86 of 255\n",
      "\n",
      "Post 87 of 255\n",
      "\n",
      "Post 88 of 255\n",
      "\n",
      "Post 89 of 255\n",
      "\n",
      "Post 90 of 255\n",
      "\n",
      "Post 91 of 255\n",
      "\n",
      "Post 92 of 255\n",
      "\n",
      "Post 93 of 255\n",
      "\n",
      "Post 94 of 255\n",
      "\n",
      "Post 95 of 255\n",
      "\n",
      "Post 96 of 255\n",
      "\n",
      "Post 97 of 255\n",
      "\n",
      "Post 98 of 255\n",
      "\n",
      "Post 99 of 255\n",
      "\n",
      "Post 100 of 255\n",
      "\n",
      "Post 101 of 255\n",
      "\n",
      "Post 102 of 255\n",
      "\n",
      "Post 103 of 255\n",
      "\n",
      "Post 104 of 255\n",
      "\n",
      "Post 105 of 255\n",
      "\n",
      "Post 106 of 255\n",
      "\n",
      "Post 107 of 255\n",
      "\n",
      "Post 108 of 255\n",
      "\n",
      "Post 109 of 255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JSON Query to explore/locations/2019740261589745/: HTTP error code 560. [retrying; skip with ^C]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 110 of 255\n",
      "\n",
      "Post 111 of 255\n",
      "\n",
      "Post 112 of 255\n",
      "\n",
      "Post 113 of 255\n",
      "\n",
      "Post 114 of 255\n",
      "\n",
      "Post 115 of 255\n",
      "\n",
      "Post 116 of 255\n",
      "\n",
      "Post 117 of 255\n",
      "\n",
      "Post 118 of 255\n",
      "\n",
      "Post 119 of 255\n",
      "\n",
      "Post 120 of 255\n",
      "\n",
      "Post 121 of 255\n",
      "\n",
      "Post 122 of 255\n",
      "\n",
      "Post 123 of 255\n",
      "\n",
      "Post 124 of 255\n",
      "\n",
      "Post 125 of 255\n",
      "\n",
      "Post 126 of 255\n",
      "\n",
      "Post 127 of 255\n",
      "\n",
      "Post 128 of 255\n",
      "\n",
      "Post 129 of 255\n",
      "\n",
      "Post 130 of 255\n",
      "\n",
      "Post 131 of 255\n",
      "\n",
      "Post 132 of 255\n",
      "\n",
      "Post 133 of 255\n",
      "\n",
      "Post 134 of 255\n",
      "\n",
      "Post 135 of 255\n",
      "\n",
      "Post 136 of 255\n",
      "\n",
      "Post 137 of 255\n",
      "\n",
      "Post 138 of 255\n",
      "\n",
      "Post 139 of 255\n",
      "\n",
      "Post 140 of 255\n",
      "\n",
      "Post 141 of 255\n",
      "\n",
      "Post 142 of 255\n",
      "\n",
      "Post 143 of 255\n",
      "\n",
      "Post 144 of 255\n",
      "\n",
      "Post 145 of 255\n",
      "\n",
      "Post 146 of 255\n",
      "\n",
      "Post 147 of 255\n",
      "\n",
      "Post 148 of 255\n",
      "\n",
      "Post 149 of 255\n",
      "\n",
      "Post 150 of 255\n",
      "\n",
      "Post 151 of 255\n",
      "\n",
      "Post 152 of 255\n",
      "\n",
      "Post 153 of 255\n",
      "\n",
      "Post 154 of 255\n",
      "\n",
      "Post 155 of 255\n",
      "\n",
      "Post 156 of 255\n",
      "\n",
      "Post 157 of 255\n",
      "\n",
      "Post 158 of 255\n",
      "\n",
      "Post 159 of 255\n",
      "\n",
      "Post 160 of 255\n",
      "\n",
      "Post 161 of 255\n",
      "\n",
      "Post 162 of 255\n",
      "\n",
      "Post 163 of 255\n",
      "\n",
      "Post 164 of 255\n",
      "\n",
      "Post 165 of 255\n",
      "\n",
      "Post 166 of 255\n",
      "\n",
      "Post 167 of 255\n",
      "\n",
      "Post 168 of 255\n",
      "\n",
      "Post 169 of 255\n",
      "\n",
      "Post 170 of 255\n",
      "\n",
      "Post 171 of 255\n",
      "\n",
      "Post 172 of 255\n",
      "\n",
      "Post 173 of 255\n",
      "\n",
      "Post 174 of 255\n",
      "\n",
      "Post 175 of 255\n",
      "\n",
      "Post 176 of 255\n",
      "\n",
      "Post 177 of 255\n",
      "\n",
      "Post 178 of 255\n",
      "\n",
      "Post 179 of 255\n",
      "\n",
      "Post 180 of 255\n",
      "\n",
      "Post 181 of 255\n",
      "\n",
      "Post 182 of 255\n",
      "\n",
      "Post 183 of 255\n",
      "\n",
      "Post 184 of 255\n",
      "\n",
      "Post 185 of 255\n",
      "\n",
      "Post 186 of 255\n",
      "\n",
      "Post 187 of 255\n",
      "\n",
      "Post 188 of 255\n",
      "\n",
      "Post 189 of 255\n",
      "\n",
      "Post 190 of 255\n",
      "\n",
      "Post 191 of 255\n",
      "\n",
      "Post 192 of 255\n",
      "\n",
      "Post 193 of 255\n",
      "\n",
      "Post 194 of 255\n",
      "\n",
      "Post 195 of 255\n",
      "\n",
      "Post 196 of 255\n",
      "\n",
      "Post 197 of 255\n",
      "\n",
      "Post 198 of 255\n",
      "\n",
      "Post 199 of 255\n",
      "\n",
      "Post 200 of 255\n",
      "\n",
      "Post 201 of 255\n",
      "\n",
      "Post 202 of 255\n",
      "\n",
      "Post 203 of 255\n",
      "\n",
      "Post 204 of 255\n",
      "\n",
      "Post 205 of 255\n",
      "\n",
      "Post 206 of 255\n",
      "\n",
      "Post 207 of 255\n",
      "\n",
      "Post 208 of 255\n",
      "\n",
      "Post 209 of 255\n",
      "\n",
      "Post 210 of 255\n",
      "\n",
      "Post 211 of 255\n",
      "\n",
      "Post 212 of 255\n",
      "\n",
      "Post 213 of 255\n",
      "\n",
      "Post 214 of 255\n",
      "\n",
      "Post 215 of 255\n",
      "\n",
      "Post 216 of 255\n",
      "\n",
      "Post 217 of 255\n",
      "\n",
      "Post 218 of 255\n",
      "\n",
      "Post 219 of 255\n",
      "\n",
      "Post 220 of 255\n",
      "\n",
      "Post 221 of 255\n",
      "\n",
      "Post 222 of 255\n",
      "\n",
      "Post 223 of 255\n",
      "\n",
      "Post 224 of 255\n",
      "\n",
      "Post 225 of 255\n",
      "\n",
      "Post 226 of 255\n",
      "\n",
      "Post 227 of 255\n",
      "\n",
      "Post 228 of 255\n",
      "\n",
      "Post 229 of 255\n",
      "\n",
      "Post 230 of 255\n",
      "\n",
      "Post 231 of 255\n",
      "\n",
      "Post 232 of 255\n",
      "\n",
      "Post 233 of 255\n",
      "\n",
      "Post 234 of 255\n",
      "\n",
      "Post 235 of 255\n",
      "\n",
      "Post 236 of 255\n",
      "\n",
      "Post 237 of 255\n",
      "\n",
      "Post 238 of 255\n",
      "\n",
      "Post 239 of 255\n",
      "\n",
      "Post 240 of 255\n",
      "\n",
      "Post 241 of 255\n",
      "\n",
      "Post 242 of 255\n",
      "\n",
      "Post 243 of 255\n",
      "\n",
      "Post 244 of 255\n",
      "\n",
      "Post 245 of 255\n",
      "\n",
      "Post 246 of 255\n",
      "\n",
      "Post 247 of 255\n",
      "\n",
      "Post 248 of 255\n",
      "\n",
      "Post 249 of 255\n",
      "\n",
      "Post 250 of 255\n",
      "\n",
      "Post 251 of 255\n",
      "\n",
      "Post 252 of 255\n",
      "\n",
      "Post 253 of 255\n",
      "\n",
      "Post 254 of 255\n",
      "\n",
      "Post 255 of 255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mypath = os.path.join(os.getcwd(), 'json')\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "# Only get jsonfiles\n",
    "index = []\n",
    "for string in onlyfiles:\n",
    "    index.append(string.endswith('.xz'))\n",
    "jsonfiles = list(itertools.compress(onlyfiles, index))\n",
    "\n",
    "count = 0\n",
    "list_dicts = []\n",
    "\n",
    "for file in jsonfiles:\n",
    "    count += 1\n",
    "    print('Post {} of {}\\n'.format(count, len(jsonfiles)))\n",
    "\n",
    "    post = instaloader.load_structure_from_file(L.context, os.path.join(mypath, file))\n",
    "    # To handle a postexception error\n",
    "    try:\n",
    "        list_dicts.append(objects_from_post(post))\n",
    "    except Exception as e:\n",
    "        print('Error getting post information:', e)\n",
    "        list_dicts.append(empty_dict(post.shortcode))\n",
    "\n",
    "df = pd.DataFrame(list_dicts)\n",
    "#df = df.join(pd.DataFrame({'company':[company] * len(list_dicts)}))\n",
    "#df = df.join(pd.DataFrame({'type':[post_type] * len(list_dicts)}))\n",
    "\n",
    "# Encoding needs to be UTF8-sig, otherwise apostrophes, emojis etc. get messed up\n",
    "df.to_csv('data.csv', encoding = 'utf-8-sig') \n",
    "\n",
    "# We round up so we minus a day\n",
    "#timeseries = df.groupby(df['date'].dt.round(\"D\") - datetime.timedelta(days = 1)).sum()\n",
    "#timeseries.to_csv(company + \"/output/\" + company + \"_\" + post_type + \"_ts.csv\")\n",
    "# return df, timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
